# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/156n5f1uNHEGJHr-T3X9UQTvrKVPZcRVL

# Aplica√ß√£o de tecnicas de Transfer Learning

### O uso do aprendizado do ImageNet(MobileNetV2), para classificar uma saida bin√°ria de gatos ou cachorro

## Criando um Dataset no Colab atraves de upload da base do Kaggle
"""

!pip install opendatasets

import opendatasets as od

# Link do dataset p√∫blico no Kaggle
dataset_url = "https://www.kaggle.com/datasets/karakaggle/kaggle-cat-vs-dog-dataset/data"

# Download do dataset
od.download(dataset_url)

"""## Manipulando um diret√≥rio para nossas imagens"""

import os

base_dir = "kaggle-cat-vs-dog-dataset/kagglecatsanddogs_3367a/PetImages"
print("Pastas dispon√≠veis:", os.listdir(base_dir))
print("Qtd de imagens em Cats:", len(os.listdir(os.path.join(base_dir, "Cat"))))
print("Qtd de imagens em Dogs:", len(os.listdir(os.path.join(base_dir, "Dog"))))

"""## Gerador de imagens com a normaliza√ß√£o"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Criando gerador de imagens com normaliza√ß√£o e data augmentation
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # separa 20% para valida√ß√£o
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Conjunto de treino
train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode="binary",
    subset="training"
)

# Conjunto de valida√ß√£o
val_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode="binary",
    subset="validation"
)

"""## Carregando o MobileNetV2

Deve-se usar o aprendizado previo com o congelamento da ultima camada, uma vez que essa constar√° a saida do resultado, para nos ser√° uma sa√≠da bin√°ria para gato, ou cachorro.
"""

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models

# Carregar MobileNetV2 sem a camada final
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(150,150,3))
base_model.trainable = False  # congela as camadas do modelo base

# Construindo o modelo final
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.5),
    layers.Dense(1, activation="sigmoid")  # sa√≠da bin√°ria
])

# Compilar o modelo
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

model.summary()

"""# Treinando um modelo

O uso de apenas dez epocas, deve-se apenas ao fato de agilizar o treino, uma vez que o projeto tem caracteristica de apenas aprender, n√£o necessariamente gerando a melhor sa√≠da.
"""

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

"""## Visualizando os resultados"""

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc)+1)

plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(epochs, acc, 'b', label="Treino")
plt.plot(epochs, val_acc, 'r', label="Valida√ß√£o")
plt.title("Acur√°cia")
plt.legend()

plt.subplot(1,2,2)
plt.plot(epochs, loss, 'b', label="Treino")
plt.plot(epochs, val_loss, 'r', label="Valida√ß√£o")
plt.title("Perda")
plt.legend()

plt.show()

"""## Testando o comportamento do aprendizado"""

import numpy as np
from tensorflow.keras.preprocessing import image

# Pegando uma imagem de exemplo
img_path = os.path.join(base_dir, "Cat", os.listdir(os.path.join(base_dir,"Cat"))[0])
img = image.load_img(img_path, target_size=(150,150))

plt.imshow(img)
plt.axis("off")
plt.show()

# Pr√©-processar a imagem
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0) / 255.0

# Fazer previs√£o
pred = model.predict(x)[0][4]
print("Predi√ß√£o:", "Cachorro üê∂" if pred > 0.5 else "Gato üê±")

model.save("cats_vs_dogs_transfer.h5")
print("Modelo salvo com sucesso!")

from google.colab import files
files.download("cats_vs_dogs_transfer.h5")

## Gerando a matriz de confus√£o para avaliar o modelo

from sklearn.metrics import confusion_matrix
import numpy as np

# Exemplo: gerar previs√µes no conjunto de valida√ß√£o
Y_pred = model.predict(val_generator)
Y_pred = (Y_pred > 0.5).astype(int)  # binariza as sa√≠das (0 ou 1)

# Verdadeiros r√≥tulos
Y_true = val_generator.classes

# Matriz de confus√£o
cm = confusion_matrix(Y_true, Y_pred)
cm
## Metricas manual

TN, FP, FN, TP = cm.ravel()

# F√≥rmulas
accuracy = (TP + TN) / (TP + TN + FP + FN)
precision = TP / (TP + FP)
recall = TP / (TP + FN)
specificity = TN / (TN + FP)
f1_score = 2 * (precision * recall) / (precision + recall)

print(f"Acur√°cia:      {accuracy:.4f}")
print(f"Precis√£o:      {precision:.4f}")
print(f"Sensibilidade: {recall:.4f}")
print(f"Especificidade:{specificity:.4f}")
print(f"F1-score:      {f1_score:.4f}")

# Visualizando as metricas
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print(f"Acur√°cia (sklearn):      {accuracy_score(Y_true, Y_pred):.4f}")
print(f"Precis√£o (sklearn):      {precision_score(Y_true, Y_pred):.4f}")
print(f"Sensibilidade (sklearn): {recall_score(Y_true, Y_pred):.4f}")
print(f"F1-score (sklearn):      {f1_score(Y_true, Y_pred):.4f}")

# Plotando a matriz com plt
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Gato (Prev.)','Cachorro (Prev.)'],
            yticklabels=['Gato (Real)','Cachorro (Real)'])
plt.xlabel("Predito")
plt.ylabel("Real")
plt.title("Matriz de Confus√£o")
plt.show()
